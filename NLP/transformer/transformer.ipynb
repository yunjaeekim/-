{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyj93\\anaconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (4.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "# from konlpy.tag import Mecab\n",
    "from nltk.tokenize import word_tokenize as en_tokenizer\n",
    "import sentencepiece as spm\n",
    "import urllib.request\n",
    "import csv\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce, repeat\n",
    "from torch.cuda import amp\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import time\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import gc\n",
    "import os\n",
    "from icecream import ic   #디버깅을 해주는 library로 파이썬에서 출력됐을 때 어떤 코드에서 출력값이 나온 것인지 알려주는 라이브러리\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "SEQ_LEN = 60\n",
    "\n",
    "\n",
    "PAD_IDX = 0\n",
    "BOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "\n",
    "\n",
    "# ENV = 'COLAB'\n",
    "#ENV = 'KAGGLE'\n",
    "ENV = 'SYSTEM'\n",
    "\n",
    "# Option for Mixed Precision\n",
    "FP16 = True\n",
    "# FP16 = False\n",
    "\n",
    "N = 2\n",
    "HIDDEN_DIM = 256\n",
    "NUM_HEAD = 8 \n",
    "INNER_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 0\n",
    "\n",
    "\n",
    "CONFIG = {\n",
    "    'VOCAB_SIZE': VOCAB_SIZE,\n",
    "    'SEQ_LEN': SEQ_LEN,\n",
    "    'N': N,\n",
    "    'HIDDEN_DIM': HIDDEN_DIM,\n",
    "    'NUM_HEAD': NUM_HEAD,\n",
    "    'INNER_DIM': INNER_DIM,\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'WEIGHT_DECAY' : WEIGHT_DECAY,\n",
    "    'LEARNING_RATE' : LEARNING_RATE,\n",
    "}\n",
    "\n",
    "\n",
    "if 'device' not in globals():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Genesis1.1  In the beginning God created the heavens and the earth.',\n",
       " 'Genesis1.2  Now the earth was formless and empty, darkness was over the surface of the deep, and the Spirit of God was hovering over the waters.',\n",
       " 'Genesis1.3  And God said, \"Let there be light,\" and there was light.',\n",
       " 'Genesis1.4  God saw that the light was good, and He separated the light from the darkness.',\n",
       " 'Genesis1.5  God called the light \"day,\" and the darkness he called \"night.\" And there was evening, and there was morning--the first day.',\n",
       " 'Genesis1.6  And God said, \"Let there be an expanse between the waters to separate water from water.\"',\n",
       " 'Genesis1.7  So God made the expanse and separated the water under the expanse from the water above it. And it was so.',\n",
       " 'Genesis1.8  God called the expanse \"sky.\" And there was evening, and there was morning--the second day.',\n",
       " 'Genesis1.9  And God said, \"Let the water under the sky be gathered to one place, and let dry ground appear.\" And it was so.',\n",
       " 'Genesis1.10  God called the dry ground \"land,\" and the gathered waters he called \"seas.\" And God saw that it was good.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = './data'\n",
    "en_train = open(os.path.join(DATASET_PATH, 'bible-all.en.txt'))\n",
    "en_train_content = en_train.read()\n",
    "en_train_list = en_train_content.split('\\n')\n",
    "\n",
    "ko_train = open(os.path.join(DATASET_PATH, 'bible-all.kr.txt'))\n",
    "ko_train_content = ko_train.read()\n",
    "ko_train_list = ko_train_content.split('\\n')\n",
    "en_train_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_raw</th>\n",
       "      <th>ko_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genesis1.1  In the beginning God created the h...</td>\n",
       "      <td>Genesis1.1  태초에 하나님이 천지를 창조하셨다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genesis1.2  Now the earth was formless and emp...</td>\n",
       "      <td>Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genesis1.3  And God said, \"Let there be light,...</td>\n",
       "      <td>Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genesis1.4  God saw that the light was good, a...</td>\n",
       "      <td>Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genesis1.5  God called the light \"day,\" and th...</td>\n",
       "      <td>Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              en_raw  \\\n",
       "0  Genesis1.1  In the beginning God created the h...   \n",
       "1  Genesis1.2  Now the earth was formless and emp...   \n",
       "2  Genesis1.3  And God said, \"Let there be light,...   \n",
       "3  Genesis1.4  God saw that the light was good, a...   \n",
       "4  Genesis1.5  God called the light \"day,\" and th...   \n",
       "\n",
       "                                              ko_raw  \n",
       "0                    Genesis1.1  태초에 하나님이 천지를 창조하셨다.  \n",
       "1  Genesis1.2  땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영...  \n",
       "2      Genesis1.3  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
       "3   Genesis1.4  그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
       "4  Genesis1.5  빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "data['en_raw'] = en_train_list\n",
    "data['ko_raw'] = ko_train_list\n",
    "data = data.reset_index(drop = True)\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['en'] = data['en_raw'].apply(lambda x: x.split(' ')[1:])\n",
    "data['en'] = data['en'].apply(lambda x: (' ').join(x))\n",
    "data['ko'] = data['ko_raw'].apply(lambda x: x.split(' ')[1:])\n",
    "data['ko'] = data['ko'].apply(lambda x: (' ').join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ko</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the beginning God created the heavens and ...</td>\n",
       "      <td>태초에 하나님이 천지를 창조하셨다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now the earth was formless and empty, darknes...</td>\n",
       "      <td>땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And God said, \"Let there be light,\" and there...</td>\n",
       "      <td>하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>God saw that the light was good, and He separ...</td>\n",
       "      <td>그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>God called the light \"day,\" and the darkness ...</td>\n",
       "      <td>빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0   In the beginning God created the heavens and ...   \n",
       "1   Now the earth was formless and empty, darknes...   \n",
       "2   And God said, \"Let there be light,\" and there...   \n",
       "3   God saw that the light was good, and He separ...   \n",
       "4   God called the light \"day,\" and the darkness ...   \n",
       "\n",
       "                                                  ko  \n",
       "0                                태초에 하나님이 천지를 창조하셨다.  \n",
       "1   땅이 혼돈하고 공허하며, 어둠이 깊음 위에 있고, 하나님의 영은 물 위에 움직이고...  \n",
       "2                  하나님이 말씀하시기를 \"빛이 생겨라\" 하시니, 빛이 생겼다.  \n",
       "3               그 빛이 하나님 보시기에 좋았다. 하나님이 빛과 어둠을 나누셔서,  \n",
       "4   빛을 낮이라고 하시고, 어둠을 밤이라고 하셨다. 저녁이 되고 아침이 되니, 하루가...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['en','ko']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 사전 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('src.txt', mode = 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(data['en']))\n",
    "with open('trg.txt', mode= 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(data['ko']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture context\n",
    "corpus = \"src.txt\"\n",
    "prefix = \"src\"\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={VOCAB_SIZE}\" +\n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" +  # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\");  # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture context\n",
    "corpus = \"trg.txt\"\n",
    "prefix = \"trg\"\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={VOCAB_SIZE}\" +\n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" +  # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" +  # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" +  # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" +  # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" +  # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\");  # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁In', '▁the', '▁beginning', '▁God', '▁created', '▁the', '▁heavens', '▁and', '▁the', '▁earth', '.']\n",
      "[502, 10, 2155, 133, 3212, 10, 1354, 19, 10, 458, 9961]\n",
      "['▁Now', '▁the', '▁earth', '▁was', '▁form', 'less', '▁and', '▁empty', ',', '▁darkness', '▁was', '▁over', '▁the', '▁surface', '▁of', '▁the', '▁deep', ',', '▁and', '▁the', '▁Spirit', '▁of', '▁God', '▁was', '▁ho', 'vering', '▁over', '▁the', '▁waters', '.']\n",
      "[589, 10, 458, 127, 3464, 636, 19, 3330, 9958, 1451, 127, 268, 10, 6810, 21, 10, 1685, 9958, 19, 10, 837, 21, 133, 127, 386, 8187, 268, 10, 1411, 9961]\n",
      "['▁And', '▁God', '▁said', ',', '▁\"', 'Let', '▁there', '▁be', '▁light', ',\"', '▁and', '▁there', '▁was', '▁light', '.']\n",
      "[288, 133, 150, 9958, 65, 1612, 250, 52, 897, 393, 19, 250, 127, 897, 9961]\n"
     ]
    }
   ],
   "source": [
    "sp_src = spm.SentencePieceProcessor()\n",
    "sp_src.Load('src.model')\n",
    "\n",
    "\n",
    "for idx in range(3):\n",
    "    sentence = data['en'][idx]\n",
    "    print(sp_src.EncodeAsPieces(sentence))\n",
    "    print(sp_src.EncodeAsIds(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_encode(tmpstr:str) -> np.array :\n",
    "    tmpstr = np.array(sp_src.EncodeAsIds(tmpstr))\n",
    "\n",
    "    # SEQ_LEN보다 길면 짜른다 \n",
    "    if len(tmpstr) > SEQ_LEN :\n",
    "        tmpstr = tmpstr[:SEQ_LEN]\n",
    "\n",
    "    # SEQ_LEN보다 작으면 padding\n",
    "    else :\n",
    "        tmpstr = np.pad(tmpstr, (0, SEQ_LEN - len(tmpstr)), 'constant', constant_values = sp_src.pad_id())\n",
    "    \n",
    "    return tmpstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 502,   10, 2155,  133, 3212,   10, 1354,   19,   10,  458, 9961,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# src_data는 data['en']를 참조한다. (동일 id)\n",
    "src_data = data['en']\n",
    "\n",
    "src_list = []\n",
    "\n",
    "for idx in range(len(src_data)):\n",
    "    src_list.append(en_encode(src_data[idx]))\n",
    "\n",
    "src_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁태', '초', '에', '▁하나님이', '▁천', '지를', '▁창조', '하셨다', '.']\n",
      "[561, 9349, 8964, 213, 369, 513, 2208, 883, 8962]\n",
      "['▁땅이', '▁혼', '돈', '하고', '▁공', '허', '하며', ',', '▁어둠이', '▁깊', '음', '▁위에', '▁있고', ',', '▁하나님의', '▁영', '은', '▁물', '▁위에', '▁움직', '이고', '▁계셨다', '.']\n",
      "[1226, 1567, 9398, 106, 440, 9291, 455, 8961, 4716, 1114, 9043, 394, 696, 8961, 194, 153, 8978, 119, 394, 5214, 411, 4486, 8962]\n",
      "['▁하나님이', '▁말씀하시기를', '▁\"', '빛이', '▁생겨', '라', '\"', '▁하시니', ',', '▁빛이', '▁생', '겼다', '.']\n",
      "[213, 2045, 32, 7888, 5865, 8983, 8995, 2921, 8961, 3057, 171, 1450, 8962]\n"
     ]
    }
   ],
   "source": [
    "sp_trg = spm.SentencePieceProcessor()\n",
    "sp_trg.Load('trg.model')\n",
    "\n",
    "\n",
    "for idx in range(3):\n",
    "    sentence = data['ko'][idx]\n",
    "    print(sp_trg.EncodeAsPieces(sentence))\n",
    "    print(sp_trg.EncodeAsIds(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ko_encode(tmpstr: str) -> np.array:\n",
    "    tmpstr = np.array(sp_trg.EncodeAsIds(tmpstr))\n",
    "    tmpstr = np.insert(tmpstr, 0, sp_trg.bos_id())\n",
    "\n",
    "    if len(tmpstr) >= SEQ_LEN:\n",
    "        # SEQ_LEN -1의 길이로 자른다\n",
    "        tmpstr = tmpstr[:SEQ_LEN-1]\n",
    "        # 마지막에 <eos> 토큰을 넣어줌으로써, 길이를 SEQ_LEN으로 맞춘다\n",
    "        tmpstr = np.pad(tmpstr, (0, 1),\n",
    "                        'constant', constant_values=sp_trg.eos_id())\n",
    "\n",
    "\n",
    "    else:\n",
    "        tmpstr = np.pad(tmpstr, (0, 1),\n",
    "                        'constant', constant_values=sp_trg.eos_id())\n",
    "        tmpstr = np.pad(tmpstr, (0, SEQ_LEN - len(tmpstr)),\n",
    "                        'constant', constant_values=sp_trg.pad_id())\n",
    "\n",
    "    return tmpstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,  561, 9349, 8964,  213,  369,  513, 2208,  883, 8962,    3,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trg_data는 data['ko']를 참조한다. (동일 id)\n",
    "trg_data = data['ko']\n",
    "\n",
    "trg_list = []\n",
    "\n",
    "for idx in range(len(trg_data)):\n",
    "    trg_list.append(ko_encode(trg_data[idx]))   \n",
    "\n",
    "trg_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train, src_valid, trg_train, trg_valid = train_test_split(src_list, trg_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(src_data) == len(trg_data)\n",
    "\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        src = self.src_data[idx]\n",
    "        trg_input = self.trg_data[idx]\n",
    "        trg_output = trg_input[1:SEQ_LEN]\n",
    "        trg_output = np.pad(trg_output, (0,1), 'constant', constant_values =0)\n",
    "        # (seq_len,)\n",
    "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
    "\n",
    "train_dataset = TrainDataset(src_train, trg_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle= True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, src_data, trg_data):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(src_data) == len(trg_data)\n",
    "\n",
    "        self.src_data = src_data\n",
    "        self.trg_data = trg_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_data)\n",
    "        \n",
    "    def __getitem__ (self, idx):\n",
    "        src = self.src_data[idx]\n",
    "        trg_input = self.trg_data[idx]\n",
    "        trg_output = trg_input[1:SEQ_LEN]\n",
    "        trg_output = np.pad(trg_output, (0,1), 'constant',constant_values= 0)\n",
    "\n",
    "        return torch.Tensor(src).long(), torch.Tensor(trg_input).long(), torch.Tensor(trg_output).long()\n",
    "\n",
    "valid_dataset = ValidDataset(src_valid, trg_valid)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle= False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask Fuction\n",
    "- padding option : 'PAD_IDX'로 지정된 패딩 토큰을 0으로 바꾸어 패딩 작업을 완료합니다.\n",
    "\n",
    "- lookahead option : \n",
    "   - repeat 함수를 통해 padding된 행렬을 seq_len x seq_len 차원으로 확장시킵니다.\n",
    "   - ones_like와 tril 메소드를 통해 해당 차원 내에서 하향 삼각행렬을 만듭니다.\n",
    "   - 이후, 하향 삼각행렬(mask)와 repeate로 만들어진 확장된 패딩 행렬(padding_mask)을 내적하여 최종 행렬을 출력합니다.\n",
    "       \n",
    "       => 이는 미래 정보를 예측에 활용되지 않게 하기 위한 transformer의 masking 기법을 적용한 최종 산출물 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mask 행렬을 반환하는 Mask Function\n",
    "Masking은 QK_T 중 srcK 의 seq_len을 중심으로 한다는 점을 알아두자!!\n",
    "\n",
    "Input\n",
    "- Tensor\n",
    "    shape (bs, srcK seq_len)\n",
    "\n",
    "Args\n",
    "- Option\n",
    "    If option is 'padding', function returns padding mask\n",
    "    If option is 'lookahead', function returns lookahead mask\n",
    "\n",
    "Output\n",
    "- Tensor (option = 'padding' )\n",
    "    shape (bs, 1, 1, srcK seq_len)\n",
    "\n",
    "\n",
    "* shape 중 (1, 1) 부분은 broad casting을 위한 것이다.\n",
    "'''\n",
    "\n",
    "def makeMask(tensor, option: str) -> torch.Tensor:\n",
    "    '''\n",
    "    tensor (bs, seq_len)\n",
    "    '''\n",
    "    if option == 'padding':\n",
    "        tmp = torch.full_like(tensor, fill_value=PAD_IDX).to(device)\n",
    "        # tmp : (bs,seq_len)\n",
    "        mask = (tensor != tmp).float()\n",
    "        # mask : (bs, seq_len)\n",
    "        mask = rearrange(mask, 'bs seq_len -> bs 1 1 seq_len ')\n",
    "\n",
    "        # mask(bs, 1, seq_len,seq_len)\n",
    "\n",
    "        '''\n",
    "        Example of mask\n",
    "        tensor([[\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
    "        '''\n",
    "\n",
    "    elif option == 'lookahead':\n",
    "        # srcQ의 seq_len과 srcK의 seq_len이 동일하다고 가정한다\n",
    "        # tensor : (bs, seq_len)\n",
    "\n",
    "        padding_mask = makeMask(tensor, 'padding')\n",
    "        padding_mask = repeat(\n",
    "            padding_mask, 'bs 1 1 k_len -> bs 1 new k_len', new=padding_mask.shape[3])\n",
    "        # padding_mask : (bs, 1, seq_len, seq_len)\n",
    "\n",
    "        '''\n",
    "        Example of padding_mask\n",
    "        tensor([[\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
    "        '''\n",
    "        mask = torch.ones_like(padding_mask)\n",
    "        mask = torch.tril(mask)\n",
    "        '''\n",
    "        Example of 'mask'\n",
    "        tensor([[\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
    "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
    "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1.]]])\n",
    "        '''\n",
    "\n",
    "        mask = mask * padding_mask\n",
    "        # ic(mask.shape)\n",
    "\n",
    "        '''\n",
    "        Example\n",
    "        tensor([[\n",
    "         [1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "         [1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
    "         [1., 1., 1., 1., 0., 0., 0., 0.]]])\n",
    "        '''\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| test.shape: torch.Size([1, 10])\n",
      "ic| test1.shape: torch.Size([1, 1, 1, 10])\n",
      "ic| test2.shape:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " padding  옵션에 대한 출력 \n",
      " => tensor([[[[1., 1., 1., 1., 1., 1., 0., 0., 0., 0.]]]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " torch.Size([1, 1, 10, 10])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookahead 옵션에 대한 출력 \n",
      " => tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "test = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n",
    "ic(test.shape)\n",
    "test1 = makeMask(test, option = 'padding')\n",
    "test2 = makeMask(test, option = 'lookahead')\n",
    "ic(test1.shape)\n",
    "print(\" padding  옵션에 대한 출력 \\n =>\", test1)\n",
    "print()\n",
    "ic(test2.shape)\n",
    "print(\"lookahead 옵션에 대한 출력 \\n =>\", test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multihead Attention\n",
    "\n",
    "- initialize\n",
    "    - Linear 선형 변환을 진행하여 더 좋은 품질의 데이터로 변환합니다.(해당 코드에서는 차원은 변하지 않습니다.)\n",
    "        \n",
    "        => 이는 학습을 통해 계속 update 되어 좋은 성능을 낼 수 있습니다.\n",
    "\n",
    "    - Dropout을 통해 과적합을 방지합니다.\n",
    "\n",
    "- forward\n",
    "    1. rearrange를 통해 multi-head를 가진 학습 데이터로 변형시킵니다.\n",
    "        - rearrange 함수는 문자열을 통해 차원을 변환시킵니다. (코드에서 '괄호'의 역할은 곱셈입니다.)\n",
    "        \n",
    "    2. Masking 후 Query와 key의 행렬을 내적하여 Energy 행렬을 만듭니다.\n",
    "\n",
    "    3. 이후 softmax 함수를 통해 Energy를 확률로 변환시킨 행렬을 생성합니다.\n",
    "    \n",
    "    4. 이를 통해 만들어진 행렬과 Value 행렬을 내적하여 최종 예측된 행렬을 생성합니다.\n",
    "    \n",
    "    5. 마지막으로 다시 rearrange 함수를 통해 Concat을 진행합니다.\n",
    "    \n",
    "    6. 최종적으로 다시 fc layer를 통해 최종 산출물을 만들어냅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Multiheadattention(nn.Module):\n",
    "    def __init__(self, hidden_dim: int, num_head: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding_dim, d_model, 512 in paper\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 8 in paper\n",
    "        self.num_head = num_head\n",
    "        # head_dim, d_key, d_query, d_value, 64 in paper (= 512 / 8)\n",
    "        self.head_dim = hidden_dim // num_head\n",
    "        self.scale = torch.sqrt(torch.FloatTensor()).to(device)\n",
    "\n",
    "        self.fcQ = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fcK = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fcV = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fcOut = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, srcQ, srcK, srcV, mask=None):\n",
    "\n",
    "        ##### SCALED DOT PRODUCT ATTENTION ######\n",
    "\n",
    "        # input : (bs, seq_len, hidden_dim)\n",
    "        Q = self.fcQ(srcQ)\n",
    "        K = self.fcK(srcK)\n",
    "        V = self.fcV(srcV)\n",
    "        \n",
    "        #rearrange : 문자열을 통해 tensor의 배열을 바꿔주는 함수이다.(띄어쓰기를 통해 구별 / 괄호는 병합과 분리를 뜻한다.)\n",
    "        Q = rearrange(\n",
    "            Q, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "        K_T = rearrange(\n",
    "            K, 'bs seq_len (num_head head_dim) -> bs num_head head_dim seq_len', num_head=self.num_head)\n",
    "        V = rearrange(\n",
    "            V, 'bs seq_len (num_head head_dim) -> bs num_head seq_len head_dim', num_head=self.num_head)\n",
    "        \n",
    "        attention_energy = torch.matmul(Q, K_T)\n",
    "        # attention_energy : (bs, num_head, q_len, k_len)\n",
    "\n",
    "        if mask is not None :\n",
    "            '''\n",
    "            mask.shape\n",
    "            if padding : (bs, 1, 1, k_len)\n",
    "            if lookahead : (bs, 1, q_len, k_len)\n",
    "            '''\n",
    "            attention_energy = torch.masked_fill(attention_energy, (mask == 0), -1e+4)\n",
    "            \n",
    "        attention_energy = torch.softmax(attention_energy, dim = -1)\n",
    "\n",
    "        result = torch.matmul(self.dropout(attention_energy),V)\n",
    "        # result (bs, num_head, seq_len, head_dim)\n",
    "\n",
    "        ##### END OF SCALED DOT PRODUCT ATTENTION ######\n",
    "\n",
    "        # CONCAT\n",
    "        result = rearrange(result, 'bs num_head seq_len head_dim -> bs seq_len (num_head head_dim)')\n",
    "        # result : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        # LINEAR\n",
    "\n",
    "        result = self.fcOut(result)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 5])\n",
      "Output shape: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "### Linear 변환 이해 코드\n",
    "# Linear는 \"마지막 차원\"에 대해 선형 변환을 적용시킨다.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 예제 입력 텐서\n",
    "batch_size = 2\n",
    "seq_len = 3\n",
    "random_dim = 5\n",
    "hidden_dim = 4\n",
    "\n",
    "# (batch_size, seq_len, hidden_dim) 형태의 입력 텐서\n",
    "input_tensor = torch.randn(batch_size, seq_len, random_dim)\n",
    "\n",
    "# nn.Linear 레이어 정의\n",
    "linear_layer = nn.Linear(random_dim, hidden_dim)  # in_features와 out_features가 같음\n",
    "\n",
    "# 선형 변환 적용\n",
    "output_tensor = linear_layer(input_tensor)\n",
    "\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Output shape: {output_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| src.shape: torch.Size([1, 10])\n",
      "ic| padding_mask.shape: torch.Size([1, 1, 1, 10])\n",
      "ic| lookahead_mask.shape: torch.Size([1, 1, 10, 10])\n",
      "ic| test_Q.shape: torch.Size([1, 10, 60])\n",
      "ic| test_K.shape: torch.Size([1, 10, 60])\n",
      "ic| test_V.shape: torch.Size([1, 10, 60])\n",
      "ic| test_layer(srcQ = test_Q, srcK = test_K, srcV = test_V, mask = padding_mask).shape: torch.Size([1, 10, 60])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 60])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST CODE #\n",
    "bs = 1\n",
    "seq_len = 10\n",
    "hidden_dim = 60\n",
    "\n",
    "src = torch.randint(1, 10000, (bs, seq_len)).to(device)\n",
    "ic(src.shape)\n",
    "# src = torch.Tensor([[1,2,3,4,5,6,0,0,0,0]])\n",
    "\n",
    "padding_mask = makeMask(src, option = 'padding')\n",
    "ic(padding_mask.shape)\n",
    "lookahead_mask = makeMask(src, option = 'lookahead')\n",
    "ic(lookahead_mask.shape)\n",
    "\n",
    "test_Q = torch.randn((bs, seq_len, hidden_dim)).to(device)\n",
    "test_K = torch.randn((bs, seq_len, hidden_dim)).to(device)\n",
    "test_V = torch.randn((bs, seq_len, hidden_dim)).to(device)\n",
    "\n",
    "ic(test_Q.shape)\n",
    "ic(test_K.shape)\n",
    "ic(test_V.shape)\n",
    "test_layer = Multiheadattention(hidden_dim=hidden_dim, num_head =2)\n",
    "ic(test_layer(srcQ = test_Q, srcK = test_K, srcV = test_V, mask = padding_mask).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positionwise Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__ (self, hidden_dim, inner_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # 512 in paper \n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 2048 in paper\n",
    "        self.inner_dim = inner_dim \n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim, inner_dim)\n",
    "        self.fc2 = nn.Linear(inner_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        output = self.fc1(output)\n",
    "        output2 = self.relu(output)\n",
    "        output2 = self.dropout(output)\n",
    "        output3 = self.fc2(output2)\n",
    "\n",
    "        return output3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer \n",
    "<img src=\"transformer.png\" alt=\"transformer architecture\" width=\"800\" height = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoder Architecture\n",
    "- Encode layer class를 만들어 위에 있는 하나의 Encoder layer를 만듭니다.\n",
    "- 이후, Encdoer Architecture 코드를 작성합니다.\n",
    "    - 여기서는 positional encoding 대신 positional embedding을 사용하였습니다.\n",
    "        \n",
    "        => 이를 통해 embedding 과정(masking 포함)을 진행하고 dropout까지 적용하였습니다.\n",
    "    - N개의 layer를 for문을 통해 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "        \n",
    "        self.multiheadattention = Multiheadattention(hidden_dim, num_head)\n",
    "        self.ffn = FFN(hidden_dim, inner_dim)\n",
    "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "    def forward(self, input, mask = None):\n",
    "\n",
    "        # input : (bs, seq_len, hidden_dim)\n",
    "        \n",
    "        # encoder attention\n",
    "        # uses only padding mask\n",
    "        output = self.multiheadattention(srcQ= input, srcK = input, srcV = input, mask = mask)\n",
    "        output = self.dropout1(output)\n",
    "        output = input + output\n",
    "        output = self.layerNorm1(output)\n",
    "\n",
    "        output_ = self.ffn(output)\n",
    "        output_ = self.dropout2(output_)\n",
    "        output = output + output_\n",
    "        output = self.layerNorm2(output)\n",
    "\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__ (self, N, hidden_dim, num_head, inner_dim,max_length=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # N : number of encoder layer repeated \n",
    "        self.N = N\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "        self.enc_layers = nn.ModuleList([EncoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        batch_size = input.shape[0]\n",
    "        seq_len = input.shape[1]\n",
    "        # input : (bs, seq_len)\n",
    "\n",
    "        mask = makeMask(input, option='padding')\n",
    "\n",
    "        pos = torch.arange(0, seq_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n",
    "        #0 부터 seq_len-1 까지의 숫자들을 (1 x seq_len)인 행렬로 만들고 이를 repeat를 통해 batch_size x seq_len 행렬로 바꿉니다.\n",
    "        # pos: [batch_size, src_len]\n",
    "\n",
    "        # embedding layer\n",
    "        output = self.dropout(self.embedding(input) + self.pos_embedding(pos))\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "\n",
    "        # Positional Embedding\n",
    "        # output = pos_embed(output)\n",
    "\n",
    "        # Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # N encoder layer\n",
    "        for layer in self.enc_layers:\n",
    "            output = layer(output, mask)\n",
    "\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoder Architecutre\n",
    "- lookahead padding을 통해 미래 정보를 예측에 적용할 수 없게 합니다.\n",
    "- finalFc를 통해 각 행렬을 단어의 사전으로 선형변환을 시켜줍니다.\n",
    "- 이후 softmax 함수를 통해 각 토큰에서의 단어 확률을 만들고\n",
    "- argmax를 통해 각 토큰에서 확률이 가장 큰 단어를 추출합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_head, inner_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "        self.multiheadattention1 = Multiheadattention(hidden_dim, num_head)\n",
    "        self.layerNorm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.multiheadattention2 = Multiheadattention(hidden_dim, num_head)\n",
    "        self.layerNorm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.ffn = FFN(hidden_dim, inner_dim)\n",
    "        self.layerNorm3 = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.1)\n",
    "        self.dropout2 = nn.Dropout(p=0.1)\n",
    "        self.dropout3 = nn.Dropout(p=0.1)\n",
    "\n",
    "    \n",
    "    def forward(self, input, enc_output, paddingMask, lookaheadMask):\n",
    "        # input : (bs, seq_len, hidden_dim)\n",
    "        # enc_output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        # first multiheadattention\n",
    "        output = self.multiheadattention1(input, input, input, lookaheadMask)\n",
    "        output = self.dropout1(output)\n",
    "        output = output + input\n",
    "        output = self.layerNorm1(output)\n",
    "\n",
    "\n",
    "        # second multiheadattention\n",
    "        output_ = self.multiheadattention2(output, enc_output, enc_output, paddingMask)\n",
    "        output_ = self.dropout2(output_)\n",
    "        output = output_ + output\n",
    "        output = self.layerNorm2(output)\n",
    "\n",
    "\n",
    "\n",
    "        # Feedforward Network\n",
    "        output_ = self.ffn(output)\n",
    "        output_ = self.dropout3(output_)\n",
    "        output = output + output_\n",
    "        output = self.layerNorm3(output)\n",
    "\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__ (self, N, hidden_dim, num_head, inner_dim, max_length=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # N : number of encoder layer repeated \n",
    "        self.N = N\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_head = num_head\n",
    "        self.inner_dim = inner_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=hidden_dim, padding_idx=0)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
    "\n",
    "        self.dec_layers = nn.ModuleList([DecoderLayer(hidden_dim, num_head, inner_dim) for _ in range(N)])\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.finalFc = nn.Linear(hidden_dim, VOCAB_SIZE)\n",
    "\n",
    "\n",
    "    def forward(self, input, enc_src, enc_output):\n",
    "\n",
    "        # input = dec_src : (bs, seq_len)\n",
    "        # enc_src : (bs, seq_len)\n",
    "        # enc_output : (bs, seq_len,hidden_dim)\n",
    "        \n",
    "        lookaheadMask = makeMask(input, option= 'lookahead')\n",
    "        paddingMask = makeMask(enc_src, option = 'padding')\n",
    "\n",
    "        # embedding layer\n",
    "        output = self.embedding(input)\n",
    "        # output = (bs, seq_len, hidden_dim)\n",
    "\n",
    "\n",
    "        # Positional Embedding\n",
    "        # output = pos_embed(output)\n",
    "\n",
    "        # Dropout\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # N decoder layer\n",
    "        for layer in self.dec_layers:\n",
    "            output = layer(output, enc_output, paddingMask, lookaheadMask)\n",
    "        # output : (bs, seq_len, hidden_dim)\n",
    "\n",
    "        logits = self.finalFc(output)\n",
    "        # logits : (bs, seq_len, VOCAB_SIZE)\n",
    "        output = torch.softmax(logits, dim = -1)\n",
    "\n",
    "        output = torch.argmax(output, dim = -1)\n",
    "        # output : (bs, seq_len), dtype=int64\n",
    "\n",
    "\n",
    "\n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, N = 2, hidden_dim = 256, num_head = 8, inner_dim = 512):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(N, hidden_dim, num_head, inner_dim)\n",
    "        self.decoder = Decoder(N, hidden_dim, num_head, inner_dim)\n",
    "\n",
    "    def forward(self, enc_src, dec_src):\n",
    "        # enc_src : (bs, seq_len)\n",
    "        # dec_src : (bs, seq_len)\n",
    "\n",
    "        # print(f'enc_src : {enc_src.shape}')\n",
    "        # print(f'dec_src : {dec_src.shape}')\n",
    "\n",
    "        enc_output = self.encoder(enc_src)\n",
    "        # enc_output : (bs, seq_len, hidden_dim)\n",
    "        logits, output = self.decoder(dec_src, enc_src, enc_output)\n",
    "        # logits = (bs, seq_len, VOCAB_SIZE) \n",
    "\n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제 훈련 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(N, HIDDEN_DIM, NUM_HEAD, INNER_DIM).to(device)\n",
    "ic.disable() #ic 출력을 비활성화 하는 함수입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Encoder: 1-1                                [-1, 60, 256]             --\n",
      "|    └─Embedding: 2-1                         [-1, 60, 256]             2,560,000\n",
      "|    └─Embedding: 2-2                         [-1, 60, 256]             25,600\n",
      "|    └─Dropout: 2-3                           [-1, 60, 256]             --\n",
      "|    └─Dropout: 2-4                           [-1, 60, 256]             --\n",
      "|    └─ModuleList: 2                          []                        --\n",
      "|    |    └─EncoderLayer: 3-1                 [-1, 60, 256]             527,104\n",
      "|    |    └─EncoderLayer: 3-2                 [-1, 60, 256]             527,104\n",
      "├─Decoder: 1-2                                [-1, 60, 10000]           --\n",
      "|    └─Embedding: 2-5                         [-1, 60, 256]             2,560,000\n",
      "|    └─Dropout: 2-6                           [-1, 60, 256]             --\n",
      "|    └─ModuleList: 2                          []                        --\n",
      "|    |    └─DecoderLayer: 3-3                 [-1, 60, 256]             790,784\n",
      "|    |    └─DecoderLayer: 3-4                 [-1, 60, 256]             790,784\n",
      "|    └─Linear: 2-7                            [-1, 60, 10000]           2,570,000\n",
      "===============================================================================================\n",
      "Total params: 10,351,376\n",
      "Trainable params: 10,351,376\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 23.31\n",
      "===============================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 6.10\n",
      "Params size (MB): 39.49\n",
      "Estimated Total Size (MB): 45.59\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Encoder: 1-1                                [-1, 60, 256]             --\n",
       "|    └─Embedding: 2-1                         [-1, 60, 256]             2,560,000\n",
       "|    └─Embedding: 2-2                         [-1, 60, 256]             25,600\n",
       "|    └─Dropout: 2-3                           [-1, 60, 256]             --\n",
       "|    └─Dropout: 2-4                           [-1, 60, 256]             --\n",
       "|    └─ModuleList: 2                          []                        --\n",
       "|    |    └─EncoderLayer: 3-1                 [-1, 60, 256]             527,104\n",
       "|    |    └─EncoderLayer: 3-2                 [-1, 60, 256]             527,104\n",
       "├─Decoder: 1-2                                [-1, 60, 10000]           --\n",
       "|    └─Embedding: 2-5                         [-1, 60, 256]             2,560,000\n",
       "|    └─Dropout: 2-6                           [-1, 60, 256]             --\n",
       "|    └─ModuleList: 2                          []                        --\n",
       "|    |    └─DecoderLayer: 3-3                 [-1, 60, 256]             790,784\n",
       "|    |    └─DecoderLayer: 3-4                 [-1, 60, 256]             790,784\n",
       "|    └─Linear: 2-7                            [-1, 60, 10000]           2,570,000\n",
       "===============================================================================================\n",
       "Total params: 10,351,376\n",
       "Trainable params: 10,351,376\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 23.31\n",
       "===============================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 6.10\n",
       "Params size (MB): 39.49\n",
       "Estimated Total Size (MB): 45.59\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "test1 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n",
    "test2 = torch.randint(low = 0, high = 1000, size = (SEQ_LEN,))\n",
    "summary(model, [(SEQ_LEN,), (SEQ_LEN,)], dtypes = [torch.int, torch.int])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.named_parameters():\n",
    "    if 'weight' in param[0] and 'layerNorm' not in param[0] :\n",
    "        torch.nn.init.xavier_uniform_(param[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(logits: torch.tensor, targets: torch.tensor):\n",
    "    return nn.CrossEntropyLoss(ignore_index=PAD_IDX)(logits.view(-1,VOCAB_SIZE), targets.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    # train 모드로 변경\n",
    "    model.train()\n",
    "\n",
    "    # for the Mixed Precision\n",
    "    # Pytorch 예제 : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n",
    "    if(FP16):\n",
    "        scaler = amp.GradScaler()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "    running_accuracy = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (src, trg_input, trg_output) in bar:\n",
    "        src = src.to(device)\n",
    "        trg_input = trg_input.to(device)\n",
    "        trg_output = trg_output.to(device)\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        if(FP16):\n",
    "            with amp.autocast(enabled=True):\n",
    "                logits, output = model(enc_src=src, dec_src=trg_input)\n",
    "                loss = criterion(logits, trg_output)\n",
    "\n",
    "                # loss를 Scale\n",
    "                # Scaled Grdients를 계산(call)하기 위해 scaled loss를 backward()\n",
    "                scaler.scale(loss).backward()\n",
    "                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "                # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "                # otherwise, optimizer.step() is skipped.\n",
    "                scaler.step(optimizer)\n",
    "\n",
    "                # Updates the scale for next iteration.\n",
    "                scaler.update()\n",
    "\n",
    "        else:\n",
    "            logits, output = model(enc_src=src, dec_src=trg_input)\n",
    "            loss = criterion(logits, trg_output)\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "        # logits (bs, seq_len, VOCAB_SIZE)\n",
    "        # trg_output (bs, seq_len)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # change learning rate by Scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # loss.item()은 loss를 Python Float으로 반환\n",
    "        # loss.item()은 batch data의 average loss이므로, sum of loss를 구하기 위해 batch_size를 곱해준다\n",
    "        running_loss += loss.item() * batch_size\n",
    "        running_accuracy = np.mean(\n",
    "            output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
    "\n",
    "        accuracy += running_accuracy\n",
    "\n",
    "        dataset_size += batch_size\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Train_Loss=epoch_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy=accuracy / float(\n",
    "                step+1)\n",
    "        )\n",
    "\n",
    "        # break\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "    # Garbage Collector\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "\n",
    "    for step, (src, trg_input, trg_output) in bar:\n",
    "        src = src.to(device)\n",
    "        trg_input = trg_input.to(device)\n",
    "        trg_output = trg_output.to(device)\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "\n",
    "        logits, output = model(enc_src = src, dec_src = trg_input)\n",
    "        loss = criterion(logits, trg_output)\n",
    "\n",
    "        running_loss += loss.item() * batch_size\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        # 실시간으로 정보를 표시하기 위한 epoch loss\n",
    "        val_loss = running_loss / dataset_size\n",
    "        running_accuracy = np.mean(output.view(-1).detach().cpu().numpy() == trg_output.view(-1).detach().cpu().numpy())\n",
    "        \n",
    "        accuracy += running_accuracy\n",
    "\n",
    "        bar.set_postfix(\n",
    "            Epoch=epoch, Valid_Loss=val_loss, LR=optimizer.param_groups[0][\"lr\"], accuracy = accuracy / float(step + 1)\n",
    "        )\n",
    "\n",
    "        # break\n",
    "\n",
    "    accuracy /= len(dataloader)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return val_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    train_dataloader,\n",
    "    valid_dataloader,\n",
    "    file_prefix=\"\",\n",
    "    early_stopping=True,\n",
    "    early_stopping_step=10,\n",
    "):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU:{}\\n\".format(torch.cuda.get_device_name()))\n",
    "\n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    history = defaultdict(list)\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "\n",
    "        train_epoch_loss, train_accuracy = train_one_epoch(\n",
    "            model,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            dataloader=train_dataloader,\n",
    "            device=device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss, val_accuracy = valid_one_epoch(\n",
    "            model, valid_dataloader, device=device, epoch=epoch\n",
    "        )\n",
    "\n",
    "        # Log metrics\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Train Loss: {train_epoch_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}], Valid Loss: {val_loss:.4f}, Valid Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Update history\n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Train Accuracy'].append(train_accuracy)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Accuracy'].append(val_accuracy)\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss <= best_loss:\n",
    "            early_stop_counter = 0\n",
    "            print(f\"Validation Loss improved ({best_loss:.4f} ---> {val_loss:.4f})\")\n",
    "\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            # Save model weights\n",
    "            model_path = f\"{file_prefix}epoch_{epoch}_loss_{best_loss:.4f}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model Saved: {model_path}\")\n",
    "\n",
    "        elif early_stopping:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter > early_stopping_step:\n",
    "                break\n",
    "\n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print(\n",
    "        \"Training complete in {:.0f}h {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 3600,\n",
    "            (time_elapsed % 3600) // 60,\n",
    "            (time_elapsed % 3600) % 60,\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Loss: {:.4f}\".format(best_loss))\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyj93\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/389 [00:00<?, ?it/s]c:\\Users\\kyj93\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "100%|██████████| 389/389 [57:55<00:00,  8.94s/it, Epoch=1, LR=9.73e-5, Train_Loss=7.93, accuracy=0.0275]    \n",
      "100%|██████████| 98/98 [02:32<00:00,  1.56s/it, Epoch=1, LR=9.73e-5, Valid_Loss=7.48, accuracy=0.0441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 7.9259, Train Accuracy: 0.0275\n",
      "Epoch [1/50], Valid Loss: 7.4763, Valid Accuracy: 0.0441\n",
      "Validation Loss improved (inf ---> 7.4763)\n",
      "Model Saved: ./model/epoch_1_loss_7.4763.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [23:13<00:00,  3.58s/it, Epoch=2, LR=8.97e-5, Train_Loss=7.19, accuracy=0.0648]\n",
      "100%|██████████| 98/98 [02:58<00:00,  1.82s/it, Epoch=2, LR=8.97e-5, Valid_Loss=6.92, accuracy=0.0669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Train Loss: 7.1871, Train Accuracy: 0.0648\n",
      "Epoch [2/50], Valid Loss: 6.9162, Valid Accuracy: 0.0669\n",
      "Validation Loss improved (7.4763 ---> 6.9162)\n",
      "Model Saved: ./model/epoch_2_loss_6.9162.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [20:20<00:00,  3.14s/it, Epoch=3, LR=7.79e-5, Train_Loss=6.74, accuracy=0.0698]\n",
      "100%|██████████| 98/98 [02:29<00:00,  1.53s/it, Epoch=3, LR=7.79e-5, Valid_Loss=6.56, accuracy=0.0732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Train Loss: 6.7404, Train Accuracy: 0.0698\n",
      "Epoch [3/50], Valid Loss: 6.5592, Valid Accuracy: 0.0732\n",
      "Validation Loss improved (6.9162 ---> 6.5592)\n",
      "Model Saved: ./model/epoch_3_loss_6.5592.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [23:58<00:00,  3.70s/it, Epoch=4, LR=6.34e-5, Train_Loss=6.43, accuracy=0.0767]\n",
      "100%|██████████| 98/98 [02:31<00:00,  1.55s/it, Epoch=4, LR=6.34e-5, Valid_Loss=6.29, accuracy=0.0798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Train Loss: 6.4254, Train Accuracy: 0.0767\n",
      "Epoch [4/50], Valid Loss: 6.2856, Valid Accuracy: 0.0798\n",
      "Validation Loss improved (6.5592 ---> 6.2856)\n",
      "Model Saved: ./model/epoch_4_loss_6.2856.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [27:33<00:00,  4.25s/it, Epoch=5, LR=4.8e-5, Train_Loss=6.19, accuracy=0.0818] \n",
      "100%|██████████| 98/98 [04:44<00:00,  2.91s/it, Epoch=5, LR=4.8e-5, Valid_Loss=6.09, accuracy=0.0845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Train Loss: 6.1879, Train Accuracy: 0.0818\n",
      "Epoch [5/50], Valid Loss: 6.0850, Valid Accuracy: 0.0845\n",
      "Validation Loss improved (6.2856 ---> 6.0850)\n",
      "Model Saved: ./model/epoch_5_loss_6.0850.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [36:49<00:00,  5.68s/it, Epoch=6, LR=3.33e-5, Train_Loss=6, accuracy=0.0862]   \n",
      "100%|██████████| 98/98 [02:40<00:00,  1.64s/it, Epoch=6, LR=3.33e-5, Valid_Loss=5.93, accuracy=0.0878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Train Loss: 6.0042, Train Accuracy: 0.0862\n",
      "Epoch [6/50], Valid Loss: 5.9284, Valid Accuracy: 0.0878\n",
      "Validation Loss improved (6.0850 ---> 5.9284)\n",
      "Model Saved: ./model/epoch_6_loss_5.9284.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [24:10<00:00,  3.73s/it, Epoch=7, LR=2.12e-5, Train_Loss=5.85, accuracy=0.0899]\n",
      "100%|██████████| 98/98 [02:34<00:00,  1.58s/it, Epoch=7, LR=2.12e-5, Valid_Loss=5.79, accuracy=0.091] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Train Loss: 5.8453, Train Accuracy: 0.0899\n",
      "Epoch [7/50], Valid Loss: 5.7902, Valid Accuracy: 0.0910\n",
      "Validation Loss improved (5.9284 ---> 5.7902)\n",
      "Model Saved: ./model/epoch_7_loss_5.7902.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [22:58<00:00,  3.54s/it, Epoch=8, LR=1.32e-5, Train_Loss=5.7, accuracy=0.0934] \n",
      "100%|██████████| 98/98 [02:37<00:00,  1.61s/it, Epoch=8, LR=1.32e-5, Valid_Loss=5.67, accuracy=0.0942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Train Loss: 5.7017, Train Accuracy: 0.0934\n",
      "Epoch [8/50], Valid Loss: 5.6670, Valid Accuracy: 0.0942\n",
      "Validation Loss improved (5.7902 ---> 5.6670)\n",
      "Model Saved: ./model/epoch_8_loss_5.6670.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [24:22<00:00,  3.76s/it, Epoch=9, LR=1e-5, Train_Loss=5.57, accuracy=0.0965]   \n",
      "100%|██████████| 98/98 [03:03<00:00,  1.87s/it, Epoch=9, LR=1e-5, Valid_Loss=5.56, accuracy=0.0967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Train Loss: 5.5726, Train Accuracy: 0.0965\n",
      "Epoch [9/50], Valid Loss: 5.5589, Valid Accuracy: 0.0967\n",
      "Validation Loss improved (5.6670 ---> 5.5589)\n",
      "Model Saved: ./model/epoch_9_loss_5.5589.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [23:00<00:00,  3.55s/it, Epoch=10, LR=1.22e-5, Train_Loss=5.45, accuracy=0.0992]\n",
      "100%|██████████| 98/98 [01:46<00:00,  1.09s/it, Epoch=10, LR=1.22e-5, Valid_Loss=5.47, accuracy=0.0984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Train Loss: 5.4524, Train Accuracy: 0.0992\n",
      "Epoch [10/50], Valid Loss: 5.4675, Valid Accuracy: 0.0984\n",
      "Validation Loss improved (5.5589 ---> 5.4675)\n",
      "Model Saved: ./model/epoch_10_loss_5.4675.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [15:37<00:00,  2.41s/it, Epoch=11, LR=1.94e-5, Train_Loss=5.34, accuracy=0.102]\n",
      "100%|██████████| 98/98 [01:20<00:00,  1.22it/s, Epoch=11, LR=1.94e-5, Valid_Loss=5.38, accuracy=0.1]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Train Loss: 5.3419, Train Accuracy: 0.1016\n",
      "Epoch [11/50], Valid Loss: 5.3819, Valid Accuracy: 0.1002\n",
      "Validation Loss improved (5.4675 ---> 5.3819)\n",
      "Model Saved: ./model/epoch_11_loss_5.3819.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:03<00:00,  2.48s/it, Epoch=12, LR=3.09e-5, Train_Loss=5.24, accuracy=0.104]\n",
      "100%|██████████| 98/98 [01:48<00:00,  1.11s/it, Epoch=12, LR=3.09e-5, Valid_Loss=5.3, accuracy=0.102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Train Loss: 5.2394, Train Accuracy: 0.1039\n",
      "Epoch [12/50], Valid Loss: 5.3037, Valid Accuracy: 0.1016\n",
      "Validation Loss improved (5.3819 ---> 5.3037)\n",
      "Model Saved: ./model/epoch_12_loss_5.3037.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:56<00:00,  2.61s/it, Epoch=13, LR=4.52e-5, Train_Loss=5.15, accuracy=0.106]\n",
      "100%|██████████| 98/98 [01:46<00:00,  1.09s/it, Epoch=13, LR=4.52e-5, Valid_Loss=5.24, accuracy=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Train Loss: 5.1458, Train Accuracy: 0.1060\n",
      "Epoch [13/50], Valid Loss: 5.2397, Valid Accuracy: 0.1028\n",
      "Validation Loss improved (5.3037 ---> 5.2397)\n",
      "Model Saved: ./model/epoch_13_loss_5.2397.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:35<00:00,  2.56s/it, Epoch=14, LR=6.06e-5, Train_Loss=5.05, accuracy=0.108]\n",
      "100%|██████████| 98/98 [01:46<00:00,  1.09s/it, Epoch=14, LR=6.06e-5, Valid_Loss=5.17, accuracy=0.105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Train Loss: 5.0544, Train Accuracy: 0.1079\n",
      "Epoch [14/50], Valid Loss: 5.1730, Valid Accuracy: 0.1045\n",
      "Validation Loss improved (5.2397 ---> 5.1730)\n",
      "Model Saved: ./model/epoch_14_loss_5.1730.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:39<00:00,  2.57s/it, Epoch=15, LR=7.54e-5, Train_Loss=4.97, accuracy=0.11] \n",
      "100%|██████████| 98/98 [01:49<00:00,  1.12s/it, Epoch=15, LR=7.54e-5, Valid_Loss=5.12, accuracy=0.106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Train Loss: 4.9695, Train Accuracy: 0.1099\n",
      "Epoch [15/50], Valid Loss: 5.1167, Valid Accuracy: 0.1056\n",
      "Validation Loss improved (5.1730 ---> 5.1167)\n",
      "Model Saved: ./model/epoch_15_loss_5.1167.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:40<00:00,  2.57s/it, Epoch=16, LR=8.78e-5, Train_Loss=4.89, accuracy=0.112]\n",
      "100%|██████████| 98/98 [01:51<00:00,  1.13s/it, Epoch=16, LR=8.78e-5, Valid_Loss=5.07, accuracy=0.107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Train Loss: 4.8882, Train Accuracy: 0.1116\n",
      "Epoch [16/50], Valid Loss: 5.0675, Valid Accuracy: 0.1068\n",
      "Validation Loss improved (5.1167 ---> 5.0675)\n",
      "Model Saved: ./model/epoch_16_loss_5.0675.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:38<00:00,  2.57s/it, Epoch=17, LR=9.63e-5, Train_Loss=4.81, accuracy=0.113]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.08s/it, Epoch=17, LR=9.63e-5, Valid_Loss=5.01, accuracy=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Train Loss: 4.8112, Train Accuracy: 0.1134\n",
      "Epoch [17/50], Valid Loss: 5.0092, Valid Accuracy: 0.1082\n",
      "Validation Loss improved (5.0675 ---> 5.0092)\n",
      "Model Saved: ./model/epoch_17_loss_5.0092.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [15:24<00:00,  2.38s/it, Epoch=18, LR=9.99e-5, Train_Loss=4.74, accuracy=0.115]\n",
      "100%|██████████| 98/98 [01:19<00:00,  1.24it/s, Epoch=18, LR=9.99e-5, Valid_Loss=4.97, accuracy=0.109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Train Loss: 4.7404, Train Accuracy: 0.1153\n",
      "Epoch [18/50], Valid Loss: 4.9660, Valid Accuracy: 0.1092\n",
      "Validation Loss improved (5.0092 ---> 4.9660)\n",
      "Model Saved: ./model/epoch_18_loss_4.9660.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [15:22<00:00,  2.37s/it, Epoch=19, LR=9.82e-5, Train_Loss=4.67, accuracy=0.117]\n",
      "100%|██████████| 98/98 [01:43<00:00,  1.06s/it, Epoch=19, LR=9.82e-5, Valid_Loss=4.92, accuracy=0.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Train Loss: 4.6723, Train Accuracy: 0.1169\n",
      "Epoch [19/50], Valid Loss: 4.9198, Valid Accuracy: 0.1104\n",
      "Validation Loss improved (4.9660 ---> 4.9198)\n",
      "Model Saved: ./model/epoch_19_loss_4.9198.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [14:12<00:00,  2.19s/it, Epoch=20, LR=9.14e-5, Train_Loss=4.61, accuracy=0.118]\n",
      "100%|██████████| 98/98 [01:54<00:00,  1.16s/it, Epoch=20, LR=9.14e-5, Valid_Loss=4.88, accuracy=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Train Loss: 4.6088, Train Accuracy: 0.1184\n",
      "Epoch [20/50], Valid Loss: 4.8798, Valid Accuracy: 0.1117\n",
      "Validation Loss improved (4.9198 ---> 4.8798)\n",
      "Model Saved: ./model/epoch_20_loss_4.8798.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:38<00:00,  2.57s/it, Epoch=21, LR=8.03e-5, Train_Loss=4.55, accuracy=0.12] \n",
      "100%|██████████| 98/98 [01:46<00:00,  1.09s/it, Epoch=21, LR=8.03e-5, Valid_Loss=4.85, accuracy=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Train Loss: 4.5468, Train Accuracy: 0.1201\n",
      "Epoch [21/50], Valid Loss: 4.8459, Valid Accuracy: 0.1127\n",
      "Validation Loss improved (4.8798 ---> 4.8459)\n",
      "Model Saved: ./model/epoch_21_loss_4.8459.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:19<00:00,  2.52s/it, Epoch=22, LR=6.62e-5, Train_Loss=4.49, accuracy=0.121]\n",
      "100%|██████████| 98/98 [01:46<00:00,  1.09s/it, Epoch=22, LR=6.62e-5, Valid_Loss=4.81, accuracy=0.114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Train Loss: 4.4882, Train Accuracy: 0.1214\n",
      "Epoch [22/50], Valid Loss: 4.8064, Valid Accuracy: 0.1139\n",
      "Validation Loss improved (4.8459 ---> 4.8064)\n",
      "Model Saved: ./model/epoch_22_loss_4.8064.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:13<00:00,  2.50s/it, Epoch=23, LR=5.08e-5, Train_Loss=4.43, accuracy=0.123]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.08s/it, Epoch=23, LR=5.08e-5, Valid_Loss=4.77, accuracy=0.115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Train Loss: 4.4313, Train Accuracy: 0.1231\n",
      "Epoch [23/50], Valid Loss: 4.7731, Valid Accuracy: 0.1147\n",
      "Validation Loss improved (4.8064 ---> 4.7731)\n",
      "Model Saved: ./model/epoch_23_loss_4.7731.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:25<00:00,  2.53s/it, Epoch=24, LR=3.58e-5, Train_Loss=4.38, accuracy=0.124]\n",
      "100%|██████████| 98/98 [01:44<00:00,  1.07s/it, Epoch=24, LR=3.58e-5, Valid_Loss=4.74, accuracy=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Train Loss: 4.3763, Train Accuracy: 0.1245\n",
      "Epoch [24/50], Valid Loss: 4.7420, Valid Accuracy: 0.1156\n",
      "Validation Loss improved (4.7731 ---> 4.7420)\n",
      "Model Saved: ./model/epoch_24_loss_4.7420.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:14<00:00,  2.50s/it, Epoch=25, LR=2.32e-5, Train_Loss=4.32, accuracy=0.126]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.08s/it, Epoch=25, LR=2.32e-5, Valid_Loss=4.72, accuracy=0.116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Train Loss: 4.3219, Train Accuracy: 0.1262\n",
      "Epoch [25/50], Valid Loss: 4.7154, Valid Accuracy: 0.1163\n",
      "Validation Loss improved (4.7420 ---> 4.7154)\n",
      "Model Saved: ./model/epoch_25_loss_4.7154.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:12<00:00,  2.50s/it, Epoch=26, LR=1.43e-5, Train_Loss=4.27, accuracy=0.128]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.08s/it, Epoch=26, LR=1.43e-5, Valid_Loss=4.69, accuracy=0.117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Train Loss: 4.2683, Train Accuracy: 0.1277\n",
      "Epoch [26/50], Valid Loss: 4.6852, Valid Accuracy: 0.1174\n",
      "Validation Loss improved (4.7154 ---> 4.6852)\n",
      "Model Saved: ./model/epoch_26_loss_4.6852.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:18<00:00,  2.52s/it, Epoch=27, LR=1.02e-5, Train_Loss=4.22, accuracy=0.129]\n",
      "100%|██████████| 98/98 [01:46<00:00,  1.08s/it, Epoch=27, LR=1.02e-5, Valid_Loss=4.66, accuracy=0.118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Train Loss: 4.2150, Train Accuracy: 0.1292\n",
      "Epoch [27/50], Valid Loss: 4.6620, Valid Accuracy: 0.1182\n",
      "Validation Loss improved (4.6852 ---> 4.6620)\n",
      "Model Saved: ./model/epoch_27_loss_4.6620.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:25<00:00,  2.53s/it, Epoch=28, LR=1.14e-5, Train_Loss=4.16, accuracy=0.131]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.07s/it, Epoch=28, LR=1.14e-5, Valid_Loss=4.64, accuracy=0.119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Train Loss: 4.1632, Train Accuracy: 0.1309\n",
      "Epoch [28/50], Valid Loss: 4.6383, Valid Accuracy: 0.1187\n",
      "Validation Loss improved (4.6620 ---> 4.6383)\n",
      "Model Saved: ./model/epoch_28_loss_4.6383.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [16:45<00:00,  2.58s/it, Epoch=29, LR=1.78e-5, Train_Loss=4.11, accuracy=0.133]\n",
      "100%|██████████| 98/98 [01:44<00:00,  1.07s/it, Epoch=29, LR=1.78e-5, Valid_Loss=4.62, accuracy=0.12] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Train Loss: 4.1128, Train Accuracy: 0.1328\n",
      "Epoch [29/50], Valid Loss: 4.6163, Valid Accuracy: 0.1198\n",
      "Validation Loss improved (4.6383 ---> 4.6163)\n",
      "Model Saved: ./model/epoch_29_loss_4.6163.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:37<00:00,  2.72s/it, Epoch=30, LR=2.85e-5, Train_Loss=4.06, accuracy=0.134]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.07s/it, Epoch=30, LR=2.85e-5, Valid_Loss=4.6, accuracy=0.121] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Train Loss: 4.0628, Train Accuracy: 0.1342\n",
      "Epoch [30/50], Valid Loss: 4.5956, Valid Accuracy: 0.1208\n",
      "Validation Loss improved (4.6163 ---> 4.5956)\n",
      "Model Saved: ./model/epoch_30_loss_4.5956.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:18<00:00,  2.67s/it, Epoch=31, LR=4.24e-5, Train_Loss=4.01, accuracy=0.136]\n",
      "100%|██████████| 98/98 [01:44<00:00,  1.07s/it, Epoch=31, LR=4.24e-5, Valid_Loss=4.58, accuracy=0.121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Train Loss: 4.0140, Train Accuracy: 0.1359\n",
      "Epoch [31/50], Valid Loss: 4.5804, Valid Accuracy: 0.1211\n",
      "Validation Loss improved (4.5956 ---> 4.5804)\n",
      "Model Saved: ./model/epoch_31_loss_4.5804.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:00<00:00,  2.62s/it, Epoch=32, LR=5.78e-5, Train_Loss=3.97, accuracy=0.138]\n",
      "100%|██████████| 98/98 [01:45<00:00,  1.07s/it, Epoch=32, LR=5.78e-5, Valid_Loss=4.56, accuracy=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Train Loss: 3.9665, Train Accuracy: 0.1375\n",
      "Epoch [32/50], Valid Loss: 4.5612, Valid Accuracy: 0.1217\n",
      "Validation Loss improved (4.5804 ---> 4.5612)\n",
      "Model Saved: ./model/epoch_32_loss_4.5612.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:29<00:00,  2.70s/it, Epoch=33, LR=7.29e-5, Train_Loss=3.92, accuracy=0.139]\n",
      "100%|██████████| 98/98 [01:43<00:00,  1.06s/it, Epoch=33, LR=7.29e-5, Valid_Loss=4.55, accuracy=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Train Loss: 3.9202, Train Accuracy: 0.1392\n",
      "Epoch [33/50], Valid Loss: 4.5481, Valid Accuracy: 0.1230\n",
      "Validation Loss improved (4.5612 ---> 4.5481)\n",
      "Model Saved: ./model/epoch_33_loss_4.5481.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:18<00:00,  2.67s/it, Epoch=34, LR=8.58e-5, Train_Loss=3.88, accuracy=0.141]\n",
      "100%|██████████| 98/98 [01:49<00:00,  1.12s/it, Epoch=34, LR=8.58e-5, Valid_Loss=4.53, accuracy=0.123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Train Loss: 3.8761, Train Accuracy: 0.1409\n",
      "Epoch [34/50], Valid Loss: 4.5325, Valid Accuracy: 0.1234\n",
      "Validation Loss improved (4.5481 ---> 4.5325)\n",
      "Model Saved: ./model/epoch_34_loss_4.5325.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:26<00:00,  2.69s/it, Epoch=35, LR=9.51e-5, Train_Loss=3.83, accuracy=0.142]\n",
      "100%|██████████| 98/98 [01:26<00:00,  1.14it/s, Epoch=35, LR=9.51e-5, Valid_Loss=4.52, accuracy=0.124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Train Loss: 3.8328, Train Accuracy: 0.1423\n",
      "Epoch [35/50], Valid Loss: 4.5242, Valid Accuracy: 0.1238\n",
      "Validation Loss improved (4.5325 ---> 4.5242)\n",
      "Model Saved: ./model/epoch_35_loss_4.5242.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [17:02<00:00,  2.63s/it, Epoch=36, LR=9.96e-5, Train_Loss=3.79, accuracy=0.144]\n",
      "100%|██████████| 98/98 [01:26<00:00,  1.13it/s, Epoch=36, LR=9.96e-5, Valid_Loss=4.5, accuracy=0.124] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Train Loss: 3.7920, Train Accuracy: 0.1438\n",
      "Epoch [36/50], Valid Loss: 4.5025, Valid Accuracy: 0.1242\n",
      "Validation Loss improved (4.5242 ---> 4.5025)\n",
      "Model Saved: ./model/epoch_36_loss_4.5025.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:49<00:00,  2.90s/it, Epoch=37, LR=9.89e-5, Train_Loss=3.75, accuracy=0.146]\n",
      "100%|██████████| 98/98 [01:27<00:00,  1.12it/s, Epoch=37, LR=9.89e-5, Valid_Loss=4.49, accuracy=0.125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Train Loss: 3.7503, Train Accuracy: 0.1456\n",
      "Epoch [37/50], Valid Loss: 4.4931, Valid Accuracy: 0.1252\n",
      "Validation Loss improved (4.5025 ---> 4.4931)\n",
      "Model Saved: ./model/epoch_37_loss_4.4931.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [21:48<00:00,  3.36s/it, Epoch=38, LR=9.3e-5, Train_Loss=3.71, accuracy=0.147] \n",
      "100%|██████████| 98/98 [02:15<00:00,  1.38s/it, Epoch=38, LR=9.3e-5, Valid_Loss=4.47, accuracy=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Train Loss: 3.7095, Train Accuracy: 0.1472\n",
      "Epoch [38/50], Valid Loss: 4.4739, Valid Accuracy: 0.1262\n",
      "Validation Loss improved (4.4931 ---> 4.4739)\n",
      "Model Saved: ./model/epoch_38_loss_4.4739.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:48<00:00,  2.90s/it, Epoch=39, LR=8.26e-5, Train_Loss=3.67, accuracy=0.149]\n",
      "100%|██████████| 98/98 [02:40<00:00,  1.64s/it, Epoch=39, LR=8.26e-5, Valid_Loss=4.46, accuracy=0.126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Train Loss: 3.6722, Train Accuracy: 0.1485\n",
      "Epoch [39/50], Valid Loss: 4.4576, Valid Accuracy: 0.1263\n",
      "Validation Loss improved (4.4739 ---> 4.4576)\n",
      "Model Saved: ./model/epoch_39_loss_4.4576.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [24:02<00:00,  3.71s/it, Epoch=40, LR=6.89e-5, Train_Loss=3.63, accuracy=0.15] \n",
      "100%|██████████| 98/98 [02:39<00:00,  1.62s/it, Epoch=40, LR=6.89e-5, Valid_Loss=4.45, accuracy=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Train Loss: 3.6319, Train Accuracy: 0.1500\n",
      "Epoch [40/50], Valid Loss: 4.4511, Valid Accuracy: 0.1272\n",
      "Validation Loss improved (4.4576 ---> 4.4511)\n",
      "Model Saved: ./model/epoch_40_loss_4.4511.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [24:31<00:00,  3.78s/it, Epoch=41, LR=5.36e-5, Train_Loss=3.59, accuracy=0.152]\n",
      "100%|██████████| 98/98 [02:36<00:00,  1.59s/it, Epoch=41, LR=5.36e-5, Valid_Loss=4.44, accuracy=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Train Loss: 3.5939, Train Accuracy: 0.1519\n",
      "Epoch [41/50], Valid Loss: 4.4383, Valid Accuracy: 0.1279\n",
      "Validation Loss improved (4.4511 ---> 4.4383)\n",
      "Model Saved: ./model/epoch_41_loss_4.4383.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [23:26<00:00,  3.61s/it, Epoch=42, LR=3.84e-5, Train_Loss=3.56, accuracy=0.153]\n",
      "100%|██████████| 98/98 [02:35<00:00,  1.59s/it, Epoch=42, LR=3.84e-5, Valid_Loss=4.43, accuracy=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Train Loss: 3.5565, Train Accuracy: 0.1534\n",
      "Epoch [42/50], Valid Loss: 4.4279, Valid Accuracy: 0.1284\n",
      "Validation Loss improved (4.4383 ---> 4.4279)\n",
      "Model Saved: ./model/epoch_42_loss_4.4279.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [24:16<00:00,  3.74s/it, Epoch=43, LR=2.52e-5, Train_Loss=3.52, accuracy=0.155]\n",
      "100%|██████████| 98/98 [02:49<00:00,  1.73s/it, Epoch=43, LR=2.52e-5, Valid_Loss=4.42, accuracy=0.128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Train Loss: 3.5160, Train Accuracy: 0.1552\n",
      "Epoch [43/50], Valid Loss: 4.4198, Valid Accuracy: 0.1284\n",
      "Validation Loss improved (4.4279 ---> 4.4198)\n",
      "Model Saved: ./model/epoch_43_loss_4.4198.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:36<00:00,  2.87s/it, Epoch=44, LR=1.56e-5, Train_Loss=3.48, accuracy=0.157]\n",
      "100%|██████████| 98/98 [02:37<00:00,  1.61s/it, Epoch=44, LR=1.56e-5, Valid_Loss=4.42, accuracy=0.129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Train Loss: 3.4764, Train Accuracy: 0.1570\n",
      "Epoch [44/50], Valid Loss: 4.4157, Valid Accuracy: 0.1292\n",
      "Validation Loss improved (4.4198 ---> 4.4157)\n",
      "Model Saved: ./model/epoch_44_loss_4.4157.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:09<00:00,  2.80s/it, Epoch=45, LR=1.06e-5, Train_Loss=3.44, accuracy=0.159]\n",
      "100%|██████████| 98/98 [02:33<00:00,  1.57s/it, Epoch=45, LR=1.06e-5, Valid_Loss=4.41, accuracy=0.13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Train Loss: 3.4392, Train Accuracy: 0.1588\n",
      "Epoch [45/50], Valid Loss: 4.4077, Valid Accuracy: 0.1297\n",
      "Validation Loss improved (4.4157 ---> 4.4077)\n",
      "Model Saved: ./model/epoch_45_loss_4.4077.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:24<00:00,  2.84s/it, Epoch=46, LR=1.08e-5, Train_Loss=3.4, accuracy=0.161] \n",
      "100%|██████████| 98/98 [02:47<00:00,  1.71s/it, Epoch=46, LR=1.08e-5, Valid_Loss=4.4, accuracy=0.13]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Train Loss: 3.3998, Train Accuracy: 0.1605\n",
      "Epoch [46/50], Valid Loss: 4.4012, Valid Accuracy: 0.1303\n",
      "Validation Loss improved (4.4077 ---> 4.4012)\n",
      "Model Saved: ./model/epoch_46_loss_4.4012.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:39<00:00,  2.88s/it, Epoch=47, LR=1.63e-5, Train_Loss=3.36, accuracy=0.163]\n",
      "100%|██████████| 98/98 [02:32<00:00,  1.56s/it, Epoch=47, LR=1.63e-5, Valid_Loss=4.4, accuracy=0.13]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Train Loss: 3.3603, Train Accuracy: 0.1627\n",
      "Epoch [47/50], Valid Loss: 4.3975, Valid Accuracy: 0.1304\n",
      "Validation Loss improved (4.4012 ---> 4.3975)\n",
      "Model Saved: ./model/epoch_47_loss_4.3975.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:15<00:00,  2.82s/it, Epoch=48, LR=2.63e-5, Train_Loss=3.32, accuracy=0.164]\n",
      "100%|██████████| 98/98 [02:36<00:00,  1.60s/it, Epoch=48, LR=2.63e-5, Valid_Loss=4.4, accuracy=0.131] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Train Loss: 3.3202, Train Accuracy: 0.1645\n",
      "Epoch [48/50], Valid Loss: 4.3969, Valid Accuracy: 0.1307\n",
      "Validation Loss improved (4.3975 ---> 4.3969)\n",
      "Model Saved: ./model/epoch_48_loss_4.3969.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:21<00:00,  2.83s/it, Epoch=49, LR=3.98e-5, Train_Loss=3.28, accuracy=0.166]\n",
      "100%|██████████| 98/98 [02:33<00:00,  1.57s/it, Epoch=49, LR=3.98e-5, Valid_Loss=4.39, accuracy=0.131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Train Loss: 3.2831, Train Accuracy: 0.1663\n",
      "Epoch [49/50], Valid Loss: 4.3939, Valid Accuracy: 0.1310\n",
      "Validation Loss improved (4.3969 ---> 4.3939)\n",
      "Model Saved: ./model/epoch_49_loss_4.3939.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [18:48<00:00,  2.90s/it, Epoch=50, LR=5.5e-5, Train_Loss=3.25, accuracy=0.168] \n",
      "100%|██████████| 98/98 [02:35<00:00,  1.58s/it, Epoch=50, LR=5.5e-5, Valid_Loss=4.39, accuracy=0.131]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Train Loss: 3.2461, Train Accuracy: 0.1681\n",
      "Epoch [50/50], Valid Loss: 4.3944, Valid Accuracy: 0.1311\n",
      "Training complete in 18h 26m 49s\n",
      "Best Loss: 4.3939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Transformer(\n",
       "   (encoder): Encoder(\n",
       "     (embedding): Embedding(10000, 256, padding_idx=0)\n",
       "     (pos_embedding): Embedding(100, 256)\n",
       "     (enc_layers): ModuleList(\n",
       "       (0): EncoderLayer(\n",
       "         (multiheadattention): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (ffn): FFN(\n",
       "           (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "           (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "           (relu): ReLU()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (1): EncoderLayer(\n",
       "         (multiheadattention): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (ffn): FFN(\n",
       "           (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "           (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "           (relu): ReLU()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (decoder): Decoder(\n",
       "     (embedding): Embedding(10000, 256, padding_idx=0)\n",
       "     (pos_embedding): Embedding(100, 256)\n",
       "     (dec_layers): ModuleList(\n",
       "       (0): DecoderLayer(\n",
       "         (multiheadattention1): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (multiheadattention2): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "           (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "           (relu): ReLU()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "         (dropout3): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (1): DecoderLayer(\n",
       "         (multiheadattention1): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (multiheadattention2): Multiheadattention(\n",
       "           (fcQ): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcK): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcV): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (fcOut): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (ffn): FFN(\n",
       "           (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "           (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "           (relu): ReLU()\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (layerNorm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (dropout1): Dropout(p=0.1, inplace=False)\n",
       "         (dropout2): Dropout(p=0.1, inplace=False)\n",
       "         (dropout3): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (finalFc): Linear(in_features=256, out_features=10000, bias=True)\n",
       "   )\n",
       " ),\n",
       " defaultdict(list,\n",
       "             {'Train Loss': [7.9258748693289505,\n",
       "               7.187146785524369,\n",
       "               6.740427612726584,\n",
       "               6.425387660469105,\n",
       "               6.187940902592683,\n",
       "               6.004182075470133,\n",
       "               5.8452753147042,\n",
       "               5.701721390779871,\n",
       "               5.572564906956696,\n",
       "               5.452388700859984,\n",
       "               5.341908379813719,\n",
       "               5.239446195179984,\n",
       "               5.145834914473712,\n",
       "               5.0544118213389115,\n",
       "               4.9694699054888645,\n",
       "               4.8881934280971935,\n",
       "               4.811152240037391,\n",
       "               4.740445212526815,\n",
       "               4.672335692474956,\n",
       "               4.608751809439398,\n",
       "               4.546846037493954,\n",
       "               4.48823498044947,\n",
       "               4.431327494912672,\n",
       "               4.376300834054345,\n",
       "               4.321879586582087,\n",
       "               4.268348924418917,\n",
       "               4.215029326137927,\n",
       "               4.163218427728678,\n",
       "               4.112763763446591,\n",
       "               4.0627752970457225,\n",
       "               4.013958917555019,\n",
       "               3.966544129958381,\n",
       "               3.9201810214218926,\n",
       "               3.876089318697463,\n",
       "               3.832761309784344,\n",
       "               3.7919641866593126,\n",
       "               3.7503191061218812,\n",
       "               3.7095356752350943,\n",
       "               3.6722117547786146,\n",
       "               3.6318679717472118,\n",
       "               3.593915350398934,\n",
       "               3.556473838129846,\n",
       "               3.515957819794131,\n",
       "               3.476398865183857,\n",
       "               3.4391902579624247,\n",
       "               3.3998068104323784,\n",
       "               3.360329976990374,\n",
       "               3.3201969353729077,\n",
       "               3.2830629033137475,\n",
       "               3.2461165062547503],\n",
       "              'Train Accuracy': [0.02747862480467764,\n",
       "               0.0648327237385957,\n",
       "               0.06978673110203805,\n",
       "               0.0767109738604097,\n",
       "               0.08178991926676416,\n",
       "               0.08623793937026399,\n",
       "               0.08986745646201925,\n",
       "               0.09338119780902929,\n",
       "               0.0965165546188485,\n",
       "               0.09919560797755259,\n",
       "               0.10159718021741679,\n",
       "               0.10389811156896349,\n",
       "               0.10596373725154154,\n",
       "               0.10787044037837937,\n",
       "               0.10987951709175531,\n",
       "               0.11158819381437225,\n",
       "               0.11337960687702671,\n",
       "               0.11525084219634732,\n",
       "               0.11686819784683347,\n",
       "               0.11835426222759879,\n",
       "               0.12005176829729328,\n",
       "               0.12138098410958215,\n",
       "               0.12308979209721582,\n",
       "               0.12447580628223875,\n",
       "               0.1261686918233446,\n",
       "               0.1276786858166575,\n",
       "               0.12919922039081258,\n",
       "               0.13089550569585154,\n",
       "               0.13276080783641653,\n",
       "               0.13417216929616757,\n",
       "               0.13585549874405628,\n",
       "               0.13753204179058084,\n",
       "               0.13915674828200347,\n",
       "               0.14091895487843806,\n",
       "               0.14232724473679784,\n",
       "               0.14379889621872752,\n",
       "               0.1456143045264379,\n",
       "               0.14724791078599395,\n",
       "               0.14854655497588926,\n",
       "               0.1500076133709696,\n",
       "               0.15186954200060476,\n",
       "               0.1534415718408186,\n",
       "               0.15518382615471213,\n",
       "               0.15703055429541138,\n",
       "               0.15881012725355784,\n",
       "               0.16054837798444152,\n",
       "               0.1627241481425474,\n",
       "               0.16449356118839994,\n",
       "               0.16633989553404918,\n",
       "               0.16813562721575362],\n",
       "              'Valid Loss': [7.4763090284360105,\n",
       "               6.916175121548973,\n",
       "               6.559195058672705,\n",
       "               6.285577010924439,\n",
       "               6.085017191484185,\n",
       "               5.928434336459477,\n",
       "               5.790150237915083,\n",
       "               5.667031184823313,\n",
       "               5.558888290879275,\n",
       "               5.4675216902454,\n",
       "               5.381893182640155,\n",
       "               5.303727981918131,\n",
       "               5.2397167950538055,\n",
       "               5.172979790228124,\n",
       "               5.116717027671236,\n",
       "               5.067528249902791,\n",
       "               5.009198609128141,\n",
       "               4.965957478261266,\n",
       "               4.919820830132528,\n",
       "               4.879794602071409,\n",
       "               4.845864620263928,\n",
       "               4.806414912854949,\n",
       "               4.773139376978344,\n",
       "               4.741977396319484,\n",
       "               4.715411319665215,\n",
       "               4.685190443554945,\n",
       "               4.661956888363496,\n",
       "               4.63833177352216,\n",
       "               4.6163055606640295,\n",
       "               4.5955516544305866,\n",
       "               4.580391789111193,\n",
       "               4.561176920527336,\n",
       "               4.54814534654113,\n",
       "               4.532539400635109,\n",
       "               4.5242249969883455,\n",
       "               4.5025140960544965,\n",
       "               4.49308013655407,\n",
       "               4.47392035787693,\n",
       "               4.4575517584974405,\n",
       "               4.4510645692399455,\n",
       "               4.438257148805835,\n",
       "               4.427860977450017,\n",
       "               4.419776579475617,\n",
       "               4.415677221617386,\n",
       "               4.407658771348716,\n",
       "               4.401182236078946,\n",
       "               4.3974577556218275,\n",
       "               4.396941702688953,\n",
       "               4.393903485028197,\n",
       "               4.394397555392495],\n",
       "              'Valid Accuracy': [0.04405845270800628,\n",
       "               0.06690296310832025,\n",
       "               0.07322327969649393,\n",
       "               0.07975352400575615,\n",
       "               0.0844586031527996,\n",
       "               0.08779087356096292,\n",
       "               0.09097699175824174,\n",
       "               0.09416249672946105,\n",
       "               0.09666282378335948,\n",
       "               0.09840867837519625,\n",
       "               0.1002422242935636,\n",
       "               0.10161871238880169,\n",
       "               0.10282983385661956,\n",
       "               0.10454850209314497,\n",
       "               0.10561939920198847,\n",
       "               0.10683358680010459,\n",
       "               0.10816285648874935,\n",
       "               0.10919082777341707,\n",
       "               0.1103602498691784,\n",
       "               0.11167745944531654,\n",
       "               0.11271094976452121,\n",
       "               0.11389631573783367,\n",
       "               0.11466162186028257,\n",
       "               0.11555734072475145,\n",
       "               0.11633899954212452,\n",
       "               0.11742277439822085,\n",
       "               0.11817254546049184,\n",
       "               0.11872179160125594,\n",
       "               0.11975282901622186,\n",
       "               0.12080001471742546,\n",
       "               0.12108945741758247,\n",
       "               0.1216710001308215,\n",
       "               0.12301335197540558,\n",
       "               0.12341194891418102,\n",
       "               0.12378111100209316,\n",
       "               0.12415333922030349,\n",
       "               0.12519459706959712,\n",
       "               0.1262309491104134,\n",
       "               0.12626794708267927,\n",
       "               0.12717695251177397,\n",
       "               0.12788890796703295,\n",
       "               0.12841485151753007,\n",
       "               0.1283541421376243,\n",
       "               0.12923309948979597,\n",
       "               0.12972265829408688,\n",
       "               0.1302565737833595,\n",
       "               0.1304415636446887,\n",
       "               0.13065435308738882,\n",
       "               0.1310134991496599,\n",
       "               0.13114943092621664]}))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_training(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=100, eta_min=1e-5),\n",
    "    device=device,\n",
    "    num_epochs=50,\n",
    "    train_dataloader= train_dataloader,\n",
    "    valid_dataloader = valid_dataloader,\n",
    "    file_prefix=\"./model/\",\n",
    "    early_stopping=True,\n",
    "    early_stopping_step=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'final.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(src_sentence):\n",
    "    # Prepare Sample Sentence\n",
    "    dec_sentence = ''\n",
    "\n",
    "    enc_src = sp_src.EncodeAsIds(src_sentence)\n",
    "    dec_src = []\n",
    "    dec_src = np.insert(dec_src, 0, sp_trg.bos_id())\n",
    "    # dec_src = ko_encode(dec_sentence)\n",
    "\n",
    "    enc_src = torch.Tensor(enc_src).view(1, -1).int().to(device)\n",
    "    dec_src = torch.Tensor(dec_src).view(1, -1).int().to(device)\n",
    "    # enc_src : (1,seq_len)\n",
    "    # dec_src : (1,seq_len)\n",
    "\n",
    "    last_token = None\n",
    "    last_token_idx = 0\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        # dec_src에 dec_output의 last token을 추가합니다\n",
    "        enc_output = model.encoder(enc_src)\n",
    "        # enc_output : (1,seq_len, hidden_dim)\n",
    "\n",
    "        dec_logits, dec_output = model.decoder(\n",
    "            input=dec_src, enc_src=enc_src, enc_output=enc_output\n",
    "        )\n",
    "        # dec_output : (1,seq_len)\n",
    "        # dec_logits : (1, seq_len, VOCAB_SIZE)\n",
    "\n",
    "        last_token = dec_output[:, last_token_idx].item()\n",
    "        last_token = torch.Tensor([last_token]).view(-1, 1).int()\n",
    "\n",
    "        # last_token : (1, 1)\n",
    "        dec_src = torch.cat((dec_src, last_token), dim=-1)\n",
    "\n",
    "        last_token_idx = last_token_idx + 1\n",
    "\n",
    "        # print(dec_src)\n",
    "        # print(sp_trg.Decode(dec_src.tolist()))\n",
    "        # print(last_token.item())\n",
    "        if last_token.item() is EOS_IDX:\n",
    "            break\n",
    "\n",
    "    # ic(dec_src.tolist())\n",
    "    return sp_trg.Decode(dec_src.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en =  All the people saw this and began to mutter, \"He has gone to be the guest of a 'sinner.' \"\n",
      "answer =  그런데 사람들이 보고서, 모두 수군거리며 말하기를 \"그가 죄인의 집에 묵으려고 들어갔다\" 하였다.\n",
      "ko = ['이 백성은 모두 예수를 모욕하고, 귀신 들린 사람이 예수께 말하였다. \"이렇게 서 있습니다.\"']\n",
      "en =  ten head of stall-fed cattle, twenty of pasture-fed cattle and a hundred sheep and goats, as well as deer, gazelles, roebucks and choice fowl.\n",
      "answer =  살진 소 열 마리와 목장 소 스무 마리와 양 백 마리이고, 그 밖에 수사슴과 노루와 암사슴과 살진 새 들이었다.\n",
      "ko = ['양 떼 가운데서, 염소 털옷과 소 떼이고, 고운 밀가루와 소와 나귀와 염소 털과 소와']\n",
      "en =  So give your servant a discerning heart to govern your people and to distinguish between right and wrong. For who is able to govern this great people of yours?\"\n",
      "answer =  그러므로 주의 종에게 지혜로운 마음을 주셔서, 주의 백성을 재판하고, 선과 악을 분별할 수 있게 해주시기를 바랍니다. 이렇게 많은 주의 백성을 누가 재판할 수 있겠습니까?\"\n",
      "ko = ['그러므로 주의 종이요, 주의 종이요, 주의 종입니다. 이 백성의 마음을 다하여 주님을 경외하겠습니까?\"']\n",
      "en =  So Samuel told him everything, hiding nothing from him. Then Eli said, \"He is the LORD; let him do what is good in his eyes.\"\n",
      "answer =  사무엘은 그에게 하나도 숨기지 않고 모든 것을 말하였다. 엘리가 말하였다. \"그분은 주님이시다! 그분께서는 뜻하신 대로 하실 것이다.\"\n",
      "ko = ['사무엘이 사울에게 말하였다. \"주님, 이 모든 것을 보았습니다. 그러나 주께서 그에게 말씀하셨다. 그 모든 일을 더 이상 더 이상 더 이상 더 이상으로 나를 찾았다. \"주께서 확실히 살아 계심을 두고 맹세하지만, 주께서 보시기에 악한 일을 저지르지 못하게 해주십시오.\"']\n",
      "en =  All these officials of yours will come to me, bowing down before me and saying, 'Go, you and all the people who follow you!' After that I will leave.\" Then Moses, hot with anger, left Pharaoh.\n",
      "answer =  이렇게 되면, 임금님의 모든 신하가 나에게 와서, 내 앞에 엎드려 '당신과 당신을 따르는 백성은 모두 나가 주시오' 하고 사정할 것입니다. 이런 일이 있은 다음에야, 내가 여기서 떠나겠습니다.\" 모세는 매우 화를 내면서, 바로 앞에서 나왔다.\n",
      "ko = [\"모든 신하가 나를 데리고 가서, 내가 그들을 데리고 가서 '내가 너희를 모아 놓고, 거기에서 떠나가서, 내가 너희를 인도하여 내 백성을 인도하겠다' 하고 말할 것이다.\"]\n",
      "en =  But we sailed from Philippi after the Feast of Unleavened Bread, and five days later joined the others at Troas, where we stayed seven days.\n",
      "answer =  우리는 무교절 뒤에 배를 타고 빌립보를 떠나, 닷새 만에 드로아에 이르러, 그들에게로 가서, 거기에서 이레 동안을 지냈다.\n",
      "ko = ['그러나 우리는 무교절을 지켜야 하고, 이레 동안 절기를 지켜야 한다. 그리고 그 뒤에, 사흘 동안 누룩을 넣지 않은 빵을 먹어야 한다.']\n",
      "en =  In the thirty-sixth year of Asa's reign Baasha king of Israel went up against Judah and fortified Ramah to prevent anyone from leaving or entering the territory of Asa king of Judah.\n",
      "answer =  아사 왕 삼십육년에 이스라엘 왕 바아사가, 유다를 치러 올라와서, 라마를 건축하고, 어느 누구도 유다의 아사 왕에게 왕래하지 못하게 하였다.\n",
      "ko = ['아사 왕 제 삼십년까지, 이스라엘의 여호아스 왕의 군대 사년에, 유다의 아사가 유다 왕 바아사가 유다의 아사가 되던 해에, 유다의 아사 왕 바아사가 되었다.']\n",
      "en =  To these four young men God gave knowledge and understanding of all kinds of literature and learning. And Daniel could understand visions and dreams of all kinds.\n",
      "answer =  하나님은 이 네 젊은이들이 지식을 얻게 하시고, 문학과 학문에 능통하게 하셨다. 그 밖에도 다니엘에게는 환상과 온갖 꿈을 해석하는 능력까지 주셨다.\n",
      "ko = ['하나님이 이 모든 일을 한 번역하면, 하나님의 형상과 그 종류대로 창조하셨다. \"이 끝날 수 있는 모든 것을, 하나님의 사람이 하나도 보이지 않는 것이 아닙니다.']\n",
      "en =  the ninth to Jeshua, the tenth to Shecaniah,\n",
      "answer =  아홉째는 예수아이고, 열째는 스가냐이고,\n",
      "ko = ['에노스 사람,']\n",
      "en =  They are from the world and therefore speak from the viewpoint of the world, and the world listens to them.\n",
      "answer =  그들은 세상에서 생겨났습니다. 그런 까닭에, 그들은 세상에 속한 말을 하고, 세상은 그들의 말을 듣습니다.\n",
      "ko = ['그들은 세상에 있는 이방 사람들 가운데서, 이 세상에 속한 모든 것을 보고, 세상에 속한 사람이 하나도 없습니다.']\n"
     ]
    }
   ],
   "source": [
    "# Prepare 10 Sample Sentence\n",
    "indices = np.random.choice(len(data['en']), 10, replace=False)\n",
    "sentences = data['en'][indices].to_list()\n",
    "answers = data['ko'][indices].to_list()\n",
    "\n",
    "for idx in range(len(sentences)):\n",
    "    sentence = sentences[idx]\n",
    "    print(f'en = {sentence}')\n",
    "    print(f'answer = {answers[idx]}')\n",
    "    print(f'ko = {predict(sentence)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
